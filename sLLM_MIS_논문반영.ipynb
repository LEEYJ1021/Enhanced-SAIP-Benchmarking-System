{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43eb58f8-3131-4df1-9101-530e87e9d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ Enhanced SAIP Benchmarking System\n",
      "   Information Systems Theory + Econometric Analysis\n",
      "================================================================================\n",
      "\n",
      "üìÇ Loading Data...\n",
      "   ‚úÖ Loaded 2700 time-series observations\n",
      "üîÑ Enhanced Data Loading and Preparation...\n",
      "   ‚úÖ Cleaned time-series data: 2692/2700 valid rows\n",
      "   ‚úÖ Processed main data: 27 records\n",
      "   ‚úÖ Available models: 9\n",
      "   ‚úÖ Available tasks: 3\n",
      "ü§ñ Creating Advanced ML-based Simulator...\n",
      "   ‚úÖ NLU model trained (R¬≤ = 0.997)\n",
      "   ‚úÖ QA model trained (R¬≤ = 0.957)\n",
      "   ‚úÖ Summarization model trained (R¬≤ = 0.798)\n",
      "   ‚úÖ Enhanced simulator ready\n",
      "üöÄ Running Comprehensive Multi-Model, Multi-Task Simulation...\n",
      "   üìã Analyzing 9 models across 3 tasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating Combinations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:59<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Completed simulation: 5400 total observations\n",
      "   ‚úÖ Generated KPIs for 54 model-task-policy combinations\n",
      "üìä Information Systems Quality Analysis (DeLone & McLean Model)...\n",
      "üéØ Technology Acceptance Model (TAM) Analysis...\n",
      "üìà Advanced Econometric Analysis...\n",
      "   üìä Estimating Production Function...\n",
      "   ‚úÖ Production Function R¬≤ = 0.283\n",
      "   üìä Technical Efficiency Analysis...\n",
      "   ‚úÖ Technical Efficiency calculated for 9 models\n",
      "   üìä Cost Function Analysis...\n",
      "   ‚úÖ Cost Function R¬≤ = 0.307\n",
      "   üìä Panel Data Analysis...\n",
      "   ‚úÖ Panel Data Model R¬≤ = 0.491\n",
      "üìä Creating Comprehensive Visualizations...\n",
      "   ‚úÖ Performance heatmap saved\n",
      "   ‚úÖ Policy effectiveness chart saved\n",
      "   ‚úÖ IS Quality dashboard saved\n",
      "   ‚úÖ TAM analysis chart saved\n",
      "   ‚úÖ Technical efficiency chart saved\n",
      "üíæ Saving Comprehensive Results...\n",
      "   ‚úÖ Excel results saved: SAIP_Analysis_Results_20251107_130251/data/comprehensive_results.xlsx\n",
      "   ‚úÖ CSV files saved\n",
      "   ‚úÖ JSON results saved\n",
      "   ‚úÖ Econometric model summaries saved\n",
      "\n",
      "================================================================================\n",
      "üéâ Enhanced SAIP Analysis Complete!\n",
      "================================================================================\n",
      "üìä Total Observations: 5,400\n",
      "ü§ñ Models Analyzed: 9\n",
      "üìã Tasks Analyzed: 3\n",
      "üìà KPI Records: 54\n",
      "üìÅ Results saved to: SAIP_Analysis_Results_20251107_130251\n",
      "\n",
      "üèÜ Best Performance:\n",
      "   Lowest P95 Latency: Qwen2.5-0.5B-Instruct (665.7 ms)\n",
      "   Most Energy Efficient: Qwen2.5-0.5B-Instruct (0.0015 Wh/req)\n",
      "\n",
      "‚úÖ Analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Enhanced SAIP Benchmarking System with Information Systems Theory & Econometric Analysis\n",
    "- Comprehensive multi-model, multi-task analysis\n",
    "- Information Systems Quality Model (DeLone & McLean)\n",
    "- Technology Acceptance Model (TAM) integration\n",
    "- Advanced econometric modeling\n",
    "- Production efficiency frontier analysis\n",
    "- Comprehensive result storage and visualization\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "from datetime import datetime\n",
    "import xlsxwriter\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class EnhancedSAIPAnalyzer:\n",
    "    \"\"\"\n",
    "    Enhanced SAIP Analyzer with Information Systems Theory and Econometric Models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results_storage = {}\n",
    "        self.econometric_models = {}\n",
    "        self.is_quality_metrics = {}\n",
    "        self.tam_metrics = {}\n",
    "        self.production_frontier = None\n",
    "        \n",
    "    def setup_directories(self):\n",
    "        \"\"\"Create directories for saving results\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.output_dir = f\"SAIP_Analysis_Results_{timestamp}\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        os.makedirs(f\"{self.output_dir}/visualizations\", exist_ok=True)\n",
    "        os.makedirs(f\"{self.output_dir}/models\", exist_ok=True)\n",
    "        os.makedirs(f\"{self.output_dir}/data\", exist_ok=True)\n",
    "        return self.output_dir\n",
    "\n",
    "    def load_and_prepare_enhanced_data(self, df_main_raw, df_hf_raw, df_ts_raw):\n",
    "        \"\"\"Enhanced data loading with comprehensive preprocessing\"\"\"\n",
    "        print(\"üîÑ Enhanced Data Loading and Preparation...\")\n",
    "        \n",
    "        # Time-series data cleaning\n",
    "        df_ts_clean = df_ts_raw.copy()\n",
    "        ts_column_mapping = {\n",
    "            'Model': 'model',\n",
    "            'Task': 'task', \n",
    "            'Sample': 'sample',\n",
    "            'Tokens Generated': 'tokens_generated',\n",
    "            'Tokens/sec': 'tokens_per_sec'\n",
    "        }\n",
    "        df_ts_clean.rename(columns=ts_column_mapping, inplace=True)\n",
    "\n",
    "        # Enhanced data type conversion\n",
    "        numeric_cols = ['latency_ms', 'tokens_generated', 'tokens_per_sec']\n",
    "        for col in numeric_cols:\n",
    "            if col in df_ts_clean.columns:\n",
    "                df_ts_clean[col] = pd.to_numeric(df_ts_clean[col], errors='coerce')\n",
    "\n",
    "        # Advanced outlier detection using IQR method\n",
    "        initial_rows = len(df_ts_clean)\n",
    "        for col in ['latency_ms', 'tokens_generated']:\n",
    "            if col in df_ts_clean.columns:\n",
    "                Q1 = df_ts_clean[col].quantile(0.25)\n",
    "                Q3 = df_ts_clean[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                df_ts_clean = df_ts_clean[\n",
    "                    (df_ts_clean[col] >= lower_bound) & \n",
    "                    (df_ts_clean[col] <= upper_bound)\n",
    "                ]\n",
    "\n",
    "        df_ts_clean.dropna(subset=['latency_ms', 'tokens_generated'], inplace=True)\n",
    "        df_ts_clean = df_ts_clean[df_ts_clean['tokens_generated'] >= 1]\n",
    "        \n",
    "        print(f\"   ‚úÖ Cleaned time-series data: {len(df_ts_clean)}/{initial_rows} valid rows\")\n",
    "\n",
    "        # Main data processing\n",
    "        df_main = df_main_raw.copy()\n",
    "        main_column_mapping = {\n",
    "            '    Model': 'model',\n",
    "            'Task': 'task',\n",
    "            'Latency Avg (ms)': 'latency_avg_ms',\n",
    "            'Latency P95 (ms)': 'latency_p95_ms',\n",
    "            'Latency Std (ms)': 'latency_std_ms',\n",
    "            'throughput_tokens_per_sec': 'throughput_tokens_per_sec',\n",
    "            'ÌååÎùºÎØ∏ÌÑ∞_b': 'parameters_b',\n",
    "            'ÏµúÎåÄ ÏãúÌÄÄÏä§ Í∏∏Ïù¥': 'max_context_length',\n",
    "            'ÏòàÏÉÅ Ï†ÑÎ†• (W)': 'estimated_power_w',\n",
    "            'CPU Memory Avg (MB)': 'cpu_memory_mb'\n",
    "        }\n",
    "        df_main.rename(columns=main_column_mapping, inplace=True)\n",
    "        \n",
    "        # Standardize model names\n",
    "        for df in [df_main, df_ts_clean]:\n",
    "            if 'model' in df.columns:\n",
    "                df['model'] = df['model'].str.strip()\n",
    "\n",
    "        # Create comprehensive analysis dataframe\n",
    "        df_final_analysis = df_main.copy()\n",
    "        \n",
    "        # Convert numeric columns\n",
    "        numeric_main_cols = ['latency_avg_ms', 'latency_p95_ms', 'latency_std_ms', \n",
    "                            'parameters_b', 'estimated_power_w', 'cpu_memory_mb',\n",
    "                            'throughput_tokens_per_sec']\n",
    "        \n",
    "        for col in numeric_main_cols:\n",
    "            if col in df_final_analysis.columns:\n",
    "                if col == 'max_context_length':\n",
    "                    df_final_analysis[col] = pd.to_numeric(\n",
    "                        df_final_analysis[col].astype(str).str.replace(',', ''),\n",
    "                        errors='coerce'\n",
    "                    )\n",
    "                else:\n",
    "                    df_final_analysis[col] = pd.to_numeric(df_final_analysis[col], errors='coerce')\n",
    "\n",
    "        print(f\"   ‚úÖ Processed main data: {len(df_final_analysis)} records\")\n",
    "        print(f\"   ‚úÖ Available models: {df_final_analysis['model'].nunique()}\")\n",
    "        print(f\"   ‚úÖ Available tasks: {df_final_analysis['task'].nunique()}\")\n",
    "        \n",
    "        return df_ts_clean, df_final_analysis\n",
    "\n",
    "    def create_advanced_simulator(self, df_ts_clean, df_final_analysis):\n",
    "        \"\"\"Advanced simulator with machine learning-based prediction\"\"\"\n",
    "        print(\"ü§ñ Creating Advanced ML-based Simulator...\")\n",
    "        \n",
    "        # Build performance prediction models for each task\n",
    "        self.task_models = {}\n",
    "        tasks = df_ts_clean['task'].unique()\n",
    "        \n",
    "        for task in tasks:\n",
    "            task_data = df_ts_clean[df_ts_clean['task'] == task].copy()\n",
    "            if len(task_data) < 10:\n",
    "                continue\n",
    "                \n",
    "            # Feature engineering\n",
    "            task_data = task_data.merge(\n",
    "                df_final_analysis[['model', 'task', 'parameters_b', 'estimated_power_w']],\n",
    "                on=['model', 'task'], \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Prepare features and targets\n",
    "            feature_cols = ['tokens_generated', 'parameters_b']\n",
    "            feature_cols = [col for col in feature_cols if col in task_data.columns]\n",
    "            \n",
    "            if len(feature_cols) > 0:\n",
    "                X = task_data[feature_cols].fillna(task_data[feature_cols].median())\n",
    "                y = task_data['latency_ms']\n",
    "                \n",
    "                # Train Random Forest model\n",
    "                rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "                rf_model.fit(X, y)\n",
    "                \n",
    "                r2 = rf_model.score(X, y)\n",
    "                self.task_models[task] = {\n",
    "                    'model': rf_model,\n",
    "                    'features': feature_cols,\n",
    "                    'r2': r2,\n",
    "                    'data': task_data\n",
    "                }\n",
    "                print(f\"   ‚úÖ {task} model trained (R¬≤ = {r2:.3f})\")\n",
    "\n",
    "        def enhanced_generate(model_name, task, max_new_tokens=50, temperature=0.0, token_callback=None):\n",
    "            \"\"\"Enhanced generation simulation with ML prediction\"\"\"\n",
    "            \n",
    "            # Try ML prediction first\n",
    "            if task in self.task_models:\n",
    "                model_info = self.task_models[task]\n",
    "                \n",
    "                # Get model features\n",
    "                model_data = df_final_analysis[\n",
    "                    (df_final_analysis['model'] == model_name) & \n",
    "                    (df_final_analysis['task'] == task)\n",
    "                ]\n",
    "                \n",
    "                if not model_data.empty:\n",
    "                    features = []\n",
    "                    for feat in model_info['features']:\n",
    "                        if feat == 'tokens_generated':\n",
    "                            features.append(max_new_tokens)\n",
    "                        elif feat == 'parameters_b':\n",
    "                            features.append(model_data['parameters_b'].iloc[0])\n",
    "                        else:\n",
    "                            features.append(0)  # Default value\n",
    "                    \n",
    "                    # Predict latency\n",
    "                    try:\n",
    "                        X_pred = np.array(features).reshape(1, -1)\n",
    "                        predicted_latency = model_info['model'].predict(X_pred)[0]\n",
    "                        \n",
    "                        # Add some realistic variance\n",
    "                        noise_factor = 0.1\n",
    "                        predicted_latency *= (1 + np.random.normal(0, noise_factor))\n",
    "                        \n",
    "                        # Estimate other metrics\n",
    "                        ttft_est = predicted_latency * 0.15\n",
    "                        generation_time = predicted_latency - ttft_est\n",
    "                        tbt_est = generation_time / max(1, max_new_tokens - 1)\n",
    "                        \n",
    "                        return {\n",
    "                            \"latency_ms\": float(max(0, predicted_latency)),\n",
    "                            \"ttft_ms\": float(max(0, ttft_est)),\n",
    "                            \"tbt_mean_ms\": float(max(0, tbt_est)),\n",
    "                            \"tbt_p95_ms\": float(max(0, tbt_est * 1.2)),\n",
    "                            \"tokens\": int(max_new_tokens)\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        pass  # Fall back to original method\n",
    "            \n",
    "            # Fallback to original sampling method\n",
    "            model_task_data = df_ts_clean[\n",
    "                (df_ts_clean['model'] == model_name) & (df_ts_clean['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if model_task_data.empty:\n",
    "                model_task_data = df_ts_clean[df_ts_clean['model'] == model_name]\n",
    "                if model_task_data.empty:\n",
    "                    return \"SIMULATION_ERROR: NO_DATA\"\n",
    "\n",
    "            sample_row = model_task_data.sample(1).iloc[0]\n",
    "            actual_latency = sample_row['latency_ms']\n",
    "            actual_tokens = sample_row['tokens_generated']\n",
    "\n",
    "            # Scale to requested tokens\n",
    "            scaling_factor = max_new_tokens / max(1, actual_tokens)\n",
    "            simulated_latency = actual_latency * (scaling_factor ** 0.8)  # Sublinear scaling\n",
    "            \n",
    "            ttft_est = simulated_latency * 0.15\n",
    "            generation_time = simulated_latency - ttft_est\n",
    "            tbt_est = generation_time / max(1, max_new_tokens - 1)\n",
    "\n",
    "            return {\n",
    "                \"latency_ms\": float(max(0, simulated_latency)),\n",
    "                \"ttft_ms\": float(max(0, ttft_est)),\n",
    "                \"tbt_mean_ms\": float(max(0, tbt_est)),\n",
    "                \"tbt_p95_ms\": float(max(0, tbt_est * 1.2)),\n",
    "                \"tokens\": int(max_new_tokens)\n",
    "            }\n",
    "\n",
    "        def enhanced_power(model_name):\n",
    "            \"\"\"Enhanced power estimation\"\"\"\n",
    "            try:\n",
    "                model_data = df_final_analysis[df_final_analysis['model'] == model_name]\n",
    "                if not model_data.empty:\n",
    "                    base_power = model_data['estimated_power_w'].iloc[0]\n",
    "                    if pd.notna(base_power):\n",
    "                        # Add load-dependent variation\n",
    "                        load_factor = np.random.uniform(0.7, 1.3)\n",
    "                        return base_power * load_factor\n",
    "                return np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "                \n",
    "        print(\"   ‚úÖ Enhanced simulator ready\")\n",
    "        return enhanced_generate, enhanced_power\n",
    "\n",
    "    def information_systems_quality_analysis(self, df_results):\n",
    "        \"\"\"\n",
    "        Information Systems Quality Analysis based on DeLone & McLean Model\n",
    "        - System Quality: Performance, reliability, response time\n",
    "        - Information Quality: Accuracy, completeness, consistency\n",
    "        - Service Quality: Responsiveness, assurance, empathy\n",
    "        \"\"\"\n",
    "        print(\"üìä Information Systems Quality Analysis (DeLone & McLean Model)...\")\n",
    "        \n",
    "        is_quality = {}\n",
    "        \n",
    "        for model in df_results['model'].unique():\n",
    "            model_data = df_results[df_results['model'] == model]\n",
    "            \n",
    "            if model_data.empty:\n",
    "                continue\n",
    "                \n",
    "            # System Quality Metrics\n",
    "            latency_mean = model_data['latency_ms'].mean()\n",
    "            latency_std = model_data['latency_ms'].std()\n",
    "            reliability = 1 / (1 + model_data['latency_ms'].std() / model_data['latency_ms'].mean())\n",
    "            availability = len(model_data) / len(model_data)  # Simulated availability\n",
    "            \n",
    "            system_quality = {\n",
    "                'performance_score': 1 / (1 + latency_mean / 1000),  # Normalized performance\n",
    "                'reliability_score': reliability,\n",
    "                'availability_score': availability,\n",
    "                'response_time_score': 1 / (1 + latency_mean / 500)\n",
    "            }\n",
    "            \n",
    "            # Information Quality Metrics\n",
    "            consistency = 1 - (latency_std / latency_mean) if latency_mean > 0 else 0\n",
    "            accuracy = 1 - min(model_data.get('error_rate', 0).mean() if 'error_rate' in model_data else 0, 1)\n",
    "            completeness = len(model_data.dropna()) / len(model_data)\n",
    "            \n",
    "            information_quality = {\n",
    "                'accuracy_score': accuracy,\n",
    "                'consistency_score': max(0, consistency),\n",
    "                'completeness_score': completeness,\n",
    "                'timeliness_score': system_quality['response_time_score']\n",
    "            }\n",
    "            \n",
    "            # Service Quality Metrics\n",
    "            energy_efficiency = 1 / (1 + model_data.get('energy_Wh', 1).mean())\n",
    "            cost_effectiveness = 1 / (1 + model_data.get('carbon_g', 1).mean())\n",
    "            \n",
    "            service_quality = {\n",
    "                'responsiveness_score': system_quality['response_time_score'],\n",
    "                'efficiency_score': energy_efficiency,\n",
    "                'cost_effectiveness_score': cost_effectiveness,\n",
    "                'user_satisfaction_score': (system_quality['performance_score'] + \n",
    "                                          information_quality['consistency_score']) / 2\n",
    "            }\n",
    "            \n",
    "            # Overall IS Quality Score\n",
    "            overall_score = (\n",
    "                np.mean(list(system_quality.values())) * 0.4 +\n",
    "                np.mean(list(information_quality.values())) * 0.3 +\n",
    "                np.mean(list(service_quality.values())) * 0.3\n",
    "            )\n",
    "            \n",
    "            is_quality[model] = {\n",
    "                'system_quality': system_quality,\n",
    "                'information_quality': information_quality,\n",
    "                'service_quality': service_quality,\n",
    "                'overall_is_quality_score': overall_score\n",
    "            }\n",
    "        \n",
    "        self.is_quality_metrics = is_quality\n",
    "        return is_quality\n",
    "\n",
    "    def technology_acceptance_model_analysis(self, df_results, df_final_analysis):\n",
    "        \"\"\"\n",
    "        Technology Acceptance Model (TAM) Analysis\n",
    "        - Perceived Usefulness (PU)\n",
    "        - Perceived Ease of Use (PEOU)\n",
    "        - Behavioral Intention to Use (BI)\n",
    "        \"\"\"\n",
    "        print(\"üéØ Technology Acceptance Model (TAM) Analysis...\")\n",
    "        \n",
    "        tam_analysis = {}\n",
    "        \n",
    "        for model in df_results['model'].unique():\n",
    "            model_data = df_results[df_results['model'] == model]\n",
    "            model_info = df_final_analysis[df_final_analysis['model'] == model]\n",
    "            \n",
    "            if model_data.empty or model_info.empty:\n",
    "                continue\n",
    "            \n",
    "            # Perceived Usefulness (PU) - based on performance and efficiency\n",
    "            avg_latency = model_data['latency_ms'].mean()\n",
    "            throughput = model_info['throughput_tokens_per_sec'].iloc[0] if 'throughput_tokens_per_sec' in model_info else 1\n",
    "            energy_efficiency = 1 / (1 + model_data.get('energy_Wh', 1).mean())\n",
    "            \n",
    "            perceived_usefulness = {\n",
    "                'performance_utility': 1 / (1 + avg_latency / 1000),\n",
    "                'efficiency_utility': energy_efficiency,\n",
    "                'throughput_utility': min(throughput / 50, 1),  # Normalized\n",
    "                'overall_usefulness': 0\n",
    "            }\n",
    "            perceived_usefulness['overall_usefulness'] = np.mean([\n",
    "                perceived_usefulness['performance_utility'],\n",
    "                perceived_usefulness['efficiency_utility'],\n",
    "                perceived_usefulness['throughput_utility']\n",
    "            ])\n",
    "            \n",
    "            # Perceived Ease of Use (PEOU) - based on consistency and simplicity\n",
    "            latency_cv = model_data['latency_ms'].std() / model_data['latency_ms'].mean()\n",
    "            complexity = model_info['parameters_b'].iloc[0] if 'parameters_b' in model_info else 1\n",
    "            memory_usage = model_info.get('cpu_memory_mb', pd.Series([1000])).iloc[0]\n",
    "            \n",
    "            perceived_ease_of_use = {\n",
    "                'consistency_ease': 1 / (1 + latency_cv),\n",
    "                'complexity_ease': 1 / (1 + complexity / 5),  # Normalized by 5B params\n",
    "                'resource_ease': 1 / (1 + memory_usage / 10000),  # Normalized by 10GB\n",
    "                'overall_ease_of_use': 0\n",
    "            }\n",
    "            perceived_ease_of_use['overall_ease_of_use'] = np.mean([\n",
    "                perceived_ease_of_use['consistency_ease'],\n",
    "                perceived_ease_of_use['complexity_ease'],\n",
    "                perceived_ease_of_use['resource_ease']\n",
    "            ])\n",
    "            \n",
    "            # Behavioral Intention to Use (BI) - TAM model prediction\n",
    "            # BI = Œ±‚ÇÅ*PU + Œ±‚ÇÇ*PEOU + Œ±‚ÇÉ*PU*PEOU\n",
    "            pu = perceived_usefulness['overall_usefulness']\n",
    "            peou = perceived_ease_of_use['overall_ease_of_use']\n",
    "            \n",
    "            behavioral_intention = 0.6 * pu + 0.3 * peou + 0.1 * pu * peou\n",
    "            \n",
    "            tam_analysis[model] = {\n",
    "                'perceived_usefulness': perceived_usefulness,\n",
    "                'perceived_ease_of_use': perceived_ease_of_use,\n",
    "                'behavioral_intention': behavioral_intention,\n",
    "                'tam_score': behavioral_intention\n",
    "            }\n",
    "        \n",
    "        self.tam_metrics = tam_analysis\n",
    "        return tam_analysis\n",
    "\n",
    "    def econometric_analysis(self, df_results, df_final_analysis):\n",
    "        \"\"\"\n",
    "        Advanced Econometric Analysis\n",
    "        - Production Function Estimation\n",
    "        - Technical Efficiency Analysis\n",
    "        - Cost Function Analysis\n",
    "        - Panel Data Analysis\n",
    "        \"\"\"\n",
    "        print(\"üìà Advanced Econometric Analysis...\")\n",
    "        \n",
    "        econometric_results = {}\n",
    "        \n",
    "        # Prepare panel data - ensure proper data types\n",
    "        panel_data = df_results.merge(\n",
    "            df_final_analysis[['model', 'task', 'parameters_b', 'estimated_power_w']],\n",
    "            on=['model', 'task'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Convert numeric columns to proper types\n",
    "        numeric_columns = ['latency_ms', 'parameters_b', 'estimated_power_w', 'energy_Wh', 'tokens']\n",
    "        for col in numeric_columns:\n",
    "            if col in panel_data.columns:\n",
    "                panel_data[col] = pd.to_numeric(panel_data[col], errors='coerce')\n",
    "        \n",
    "        # 1. Production Function Analysis (Cobb-Douglas)\n",
    "        # Output = A * (Parameters)^Œ± * (Power)^Œ≤\n",
    "        print(\"   üìä Estimating Production Function...\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare variables for production function\n",
    "            prod_data = panel_data.dropna(subset=['latency_ms', 'parameters_b', 'estimated_power_w'])\n",
    "            \n",
    "            if len(prod_data) > 10:\n",
    "                # Ensure all data is numeric\n",
    "                prod_data = prod_data.copy()\n",
    "                prod_data['log_output'] = np.log(1 / prod_data['latency_ms'].astype(float))  # Higher output = lower latency\n",
    "                prod_data['log_params'] = np.log(prod_data['parameters_b'].astype(float))\n",
    "                prod_data['log_power'] = np.log(prod_data['estimated_power_w'].astype(float))\n",
    "                \n",
    "                # Estimate production function\n",
    "                X_prod = prod_data[['log_params', 'log_power']].astype(float)\n",
    "                X_prod = sm.add_constant(X_prod)\n",
    "                y_prod = prod_data['log_output'].astype(float)\n",
    "                \n",
    "                prod_model = sm.OLS(y_prod, X_prod).fit()\n",
    "                \n",
    "                econometric_results['production_function'] = {\n",
    "                    'model': prod_model,\n",
    "                    'parameters_elasticity': prod_model.params.get('log_params', 0),\n",
    "                    'power_elasticity': prod_model.params.get('log_power', 0),\n",
    "                    'constant': prod_model.params.get('const', 0),\n",
    "                    'r_squared': prod_model.rsquared,\n",
    "                    'summary': prod_model.summary()\n",
    "                }\n",
    "                \n",
    "                print(f\"   ‚úÖ Production Function R¬≤ = {prod_model.rsquared:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Production Function estimation failed: {e}\")\n",
    "        \n",
    "        # 2. Technical Efficiency Analysis using Data Envelopment Analysis (DEA) approach\n",
    "        print(\"   üìä Technical Efficiency Analysis...\")\n",
    "        \n",
    "        try:\n",
    "            efficiency_data = panel_data.groupby('model').agg({\n",
    "                'latency_ms': 'mean',\n",
    "                'energy_Wh': lambda x: x.dropna().mean() if not x.dropna().empty else np.nan,\n",
    "                'parameters_b': 'first',\n",
    "                'tokens': 'mean'\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Ensure numeric types\n",
    "            for col in ['latency_ms', 'energy_Wh', 'parameters_b', 'tokens']:\n",
    "                if col in efficiency_data.columns:\n",
    "                    efficiency_data[col] = pd.to_numeric(efficiency_data[col], errors='coerce')\n",
    "            \n",
    "            # Calculate efficiency scores (lower latency and energy = higher efficiency)\n",
    "            min_latency = efficiency_data['latency_ms'].min()\n",
    "            min_energy = efficiency_data['energy_Wh'].min()\n",
    "            \n",
    "            efficiency_data['latency_efficiency'] = min_latency / efficiency_data['latency_ms']\n",
    "            efficiency_data['energy_efficiency'] = min_energy / efficiency_data['energy_Wh'].fillna(min_energy)\n",
    "            efficiency_data['overall_efficiency'] = (efficiency_data['latency_efficiency'] * 0.6 + \n",
    "                                                   efficiency_data['energy_efficiency'] * 0.4)\n",
    "            \n",
    "            econometric_results['technical_efficiency'] = efficiency_data\n",
    "            print(f\"   ‚úÖ Technical Efficiency calculated for {len(efficiency_data)} models\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Technical Efficiency analysis failed: {e}\")\n",
    "        \n",
    "        # 3. Cost Function Analysis\n",
    "        print(\"   üìä Cost Function Analysis...\")\n",
    "        \n",
    "        try:\n",
    "            # Cost = f(Output, Input Prices, Technology)\n",
    "            cost_data = panel_data.dropna(subset=['energy_Wh', 'latency_ms', 'parameters_b'])\n",
    "            \n",
    "            if len(cost_data) > 10:\n",
    "                # Ensure numeric types\n",
    "                cost_data = cost_data.copy()\n",
    "                cost_data['total_cost'] = cost_data['energy_Wh'].astype(float) * 0.1 + cost_data['parameters_b'].astype(float) * 0.01  # Simulated cost\n",
    "                cost_data['log_cost'] = np.log(cost_data['total_cost'] + 1e-6)\n",
    "                cost_data['log_output'] = np.log(1 / cost_data['latency_ms'].astype(float))\n",
    "                \n",
    "                X_cost = sm.add_constant(cost_data[['log_output']].astype(float))\n",
    "                y_cost = cost_data['log_cost'].astype(float)\n",
    "                \n",
    "                cost_model = sm.OLS(y_cost, X_cost).fit()\n",
    "                \n",
    "                econometric_results['cost_function'] = {\n",
    "                    'model': cost_model,\n",
    "                    'output_elasticity': cost_model.params.get('log_output', 0),\n",
    "                    'r_squared': cost_model.rsquared,\n",
    "                    'summary': cost_model.summary()\n",
    "                }\n",
    "                \n",
    "                print(f\"   ‚úÖ Cost Function R¬≤ = {cost_model.rsquared:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Cost Function estimation failed: {e}\")\n",
    "        \n",
    "        # 4. Panel Data Fixed Effects Model - FIXED VERSION\n",
    "        print(\"   üìä Panel Data Analysis...\")\n",
    "        \n",
    "        try:\n",
    "            # Create dummy variables for models (fixed effects)\n",
    "            panel_reg_data = panel_data.dropna(subset=['latency_ms', 'parameters_b'])\n",
    "            \n",
    "            if len(panel_reg_data) > 20:\n",
    "                # Ensure numeric types for the main variables\n",
    "                panel_reg_data = panel_reg_data.copy()\n",
    "                panel_reg_data['latency_ms'] = panel_reg_data['latency_ms'].astype(float)\n",
    "                panel_reg_data['parameters_b'] = panel_reg_data['parameters_b'].astype(float)\n",
    "                \n",
    "                # Create model dummies and ensure they are numeric\n",
    "                model_dummies = pd.get_dummies(panel_reg_data['model'], prefix='model').astype(float)\n",
    "                task_dummies = pd.get_dummies(panel_reg_data['task'], prefix='task').astype(float)\n",
    "                \n",
    "                # Combine all features and ensure they are numeric\n",
    "                X_panel = pd.concat([\n",
    "                    panel_reg_data[['parameters_b']],\n",
    "                    model_dummies.iloc[:, :-1],  # Drop one dummy to avoid multicollinearity\n",
    "                    task_dummies.iloc[:, :-1]\n",
    "                ], axis=1)\n",
    "                \n",
    "                # Ensure all columns are numeric\n",
    "                for col in X_panel.columns:\n",
    "                    X_panel[col] = pd.to_numeric(X_panel[col], errors='coerce')\n",
    "                \n",
    "                X_panel = sm.add_constant(X_panel)\n",
    "                y_panel = panel_reg_data['latency_ms'].astype(float)\n",
    "                \n",
    "                # Drop any remaining NaN values after conversion\n",
    "                valid_mask = ~(X_panel.isna().any(axis=1) | y_panel.isna())\n",
    "                X_panel_clean = X_panel[valid_mask]\n",
    "                y_panel_clean = y_panel[valid_mask]\n",
    "                \n",
    "                if len(X_panel_clean) > 10:  # Ensure we have enough data\n",
    "                    panel_model = sm.OLS(y_panel_clean, X_panel_clean).fit()\n",
    "                    \n",
    "                    econometric_results['panel_data_model'] = {\n",
    "                        'model': panel_model,\n",
    "                        'r_squared': panel_model.rsquared,\n",
    "                        'summary': panel_model.summary()\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   ‚úÖ Panel Data Model R¬≤ = {panel_model.rsquared:.3f}\")\n",
    "                else:\n",
    "                    print(\"   ‚ö†Ô∏è Not enough valid data for panel data analysis after cleaning\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è Not enough data for panel data analysis\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Panel Data analysis failed: {e}\")\n",
    "        \n",
    "        self.econometric_models = econometric_results\n",
    "        return econometric_results\n",
    "\n",
    "    def comprehensive_simulation(self, generate_fn, power_fn, df_final_analysis, df_ts_clean):\n",
    "        \"\"\"\n",
    "        Comprehensive simulation across all models and tasks\n",
    "        \"\"\"\n",
    "        print(\"üöÄ Running Comprehensive Multi-Model, Multi-Task Simulation...\")\n",
    "        \n",
    "        all_results = []\n",
    "        all_kpis = []\n",
    "        \n",
    "        models = df_final_analysis['model'].unique()\n",
    "        tasks = df_final_analysis['task'].unique()\n",
    "        \n",
    "        print(f\"   üìã Analyzing {len(models)} models across {len(tasks)} tasks\")\n",
    "        \n",
    "        # Progress tracking\n",
    "        total_combinations = len(models) * len(tasks)\n",
    "        progress_bar = tqdm(total=total_combinations, desc=\"Simulating Combinations\")\n",
    "        \n",
    "        for model in models:\n",
    "            for task in tasks:\n",
    "                # Check if combination has data\n",
    "                has_data = not df_ts_clean[\n",
    "                    (df_ts_clean['model'] == model) & (df_ts_clean['task'] == task)\n",
    "                ].empty\n",
    "                \n",
    "                if not has_data:\n",
    "                    progress_bar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Run simulation for this model-task combination\n",
    "                try:\n",
    "                    # Baseline simulation\n",
    "                    df_baseline = self.simulate_saip_enhanced(\n",
    "                        generate_fn, model, task, steps=100, \n",
    "                        energy_fn=power_fn, apply_policy=False\n",
    "                    )\n",
    "                    \n",
    "                    # SAIP simulation\n",
    "                    df_saip = self.simulate_saip_enhanced(\n",
    "                        generate_fn, model, task, steps=100,\n",
    "                        energy_fn=power_fn, apply_policy=True,\n",
    "                        targets={\"max_p95_ms\": 2000, \"max_cv\": 0.3, \"max_power_W\": 15.0}\n",
    "                    )\n",
    "                    \n",
    "                    # Add metadata\n",
    "                    for df, policy_type in [(df_baseline, 'baseline'), (df_saip, 'saip')]:\n",
    "                        if not df.empty:\n",
    "                            df['policy_type'] = policy_type\n",
    "                            df['model_task_combination'] = f\"{model}_{task}\"\n",
    "                            all_results.append(df)\n",
    "                    \n",
    "                    # Aggregate KPIs\n",
    "                    if not df_baseline.empty and not df_saip.empty:\n",
    "                        for df, policy_type in [(df_baseline, 'baseline'), (df_saip, 'saip')]:\n",
    "                            kpis = self.aggregate_enhanced_kpis(df, model, task, policy_type)\n",
    "                            all_kpis.append(kpis)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è Error in {model}-{task}: {e}\")\n",
    "                \n",
    "                progress_bar.update(1)\n",
    "        \n",
    "        progress_bar.close()\n",
    "        \n",
    "        # Combine all results\n",
    "        df_all_results = pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame()\n",
    "        df_all_kpis = pd.DataFrame(all_kpis) if all_kpis else pd.DataFrame()\n",
    "        \n",
    "        print(f\"   ‚úÖ Completed simulation: {len(df_all_results)} total observations\")\n",
    "        print(f\"   ‚úÖ Generated KPIs for {len(df_all_kpis)} model-task-policy combinations\")\n",
    "        \n",
    "        return df_all_results, df_all_kpis\n",
    "\n",
    "    def simulate_saip_enhanced(self, generate_fn, model, task, steps=100, init_max_new_tokens=50, \n",
    "                             init_temp=0.2, targets=None, energy_fn=None, apply_policy=True):\n",
    "        \"\"\"Enhanced SAIP simulation with better policy logic\"\"\"\n",
    "        \n",
    "        if targets is None:\n",
    "            targets = {\"max_p95_ms\": 2000, \"max_cv\": 0.4, \"max_power_W\": 10.0}\n",
    "            \n",
    "        history = []\n",
    "        lat_hist = []\n",
    "        pwr_hist = []\n",
    "        max_nt = init_max_new_tokens\n",
    "        temp = init_temp\n",
    "        \n",
    "        for i in range(steps):\n",
    "            try:\n",
    "                # Run generation\n",
    "                m = generate_fn(model, task, max_new_tokens=max_nt, temperature=temp)\n",
    "                \n",
    "                if not m or isinstance(m, str):\n",
    "                    continue\n",
    "\n",
    "                lat_hist.append(m[\"latency_ms\"])\n",
    "                power_W = energy_fn(model) if energy_fn else np.nan\n",
    "                pwr_hist.append(power_W)\n",
    "                \n",
    "                # Calculate moving statistics\n",
    "                window = min(30, len(lat_hist))\n",
    "                lat_window = lat_hist[-window:]\n",
    "                \n",
    "                cv = np.std(lat_window) / np.mean(lat_window) if np.mean(lat_window) > 0 else 0\n",
    "                p95 = np.percentile(lat_window, 95) if len(lat_window) >= 5 else m[\"latency_ms\"]\n",
    "                \n",
    "                state = {\n",
    "                    \"cv\": cv, \"p95_ms\": p95, \"power_W\": power_W,\n",
    "                    \"max_new_tokens\": max_nt, \"temperature\": temp\n",
    "                }\n",
    "                \n",
    "                if apply_policy:\n",
    "                    actions = self.enhanced_saip_policy(state, targets)\n",
    "                    max_nt = actions[\"max_new_tokens\"]\n",
    "                    temp = actions[\"temperature\"]\n",
    "                    if actions[\"throttle_ms\"] > 0:\n",
    "                        time.sleep(actions[\"throttle_ms\"] / 1000.0)\n",
    "                else:\n",
    "                    actions = {\"max_new_tokens\": max_nt, \"throttle_ms\": 0, \"temperature\": temp}\n",
    "\n",
    "                # Calculate energy and carbon\n",
    "                duration_s = m[\"latency_ms\"] / 1000.0\n",
    "                energy_Wh = power_W * (duration_s / 3600.0) if pd.notna(power_W) else np.nan\n",
    "                carbon_factor = 0.45  # kg CO2 per kWh\n",
    "                carbon_g = (energy_Wh / 1000.0) * carbon_factor * 1e3 if pd.notna(energy_Wh) else np.nan\n",
    "\n",
    "                history.append({\n",
    "                    **m, **state, **actions, \n",
    "                    \"step\": i, \"model\": model, \"task\": task,\n",
    "                    \"power_W_mean\": power_W, \"energy_Wh\": energy_Wh, \"carbon_g\": carbon_g\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "        return pd.DataFrame(history)\n",
    "\n",
    "    def enhanced_saip_policy(self, state, targets):\n",
    "        \"\"\"Enhanced SAIP policy with more sophisticated logic\"\"\"\n",
    "        \n",
    "        actions = {\n",
    "            \"max_new_tokens\": state.get(\"max_new_tokens\", 50),\n",
    "            \"throttle_ms\": 0,\n",
    "            \"temperature\": state.get(\"temperature\", 0.0)\n",
    "        }\n",
    "        \n",
    "        # Adaptive response based on multiple criteria\n",
    "        p95_violation = state.get(\"p95_ms\", 0) > targets.get(\"max_p95_ms\", 2000)\n",
    "        cv_violation = state.get(\"cv\", 0) > targets.get(\"max_cv\", 0.4)\n",
    "        power_violation = state.get(\"power_W\", 0) > targets.get(\"max_power_W\", 10.0)\n",
    "        \n",
    "        # Count violations for graduated response\n",
    "        violations = sum([p95_violation, cv_violation, power_violation])\n",
    "        \n",
    "        if violations >= 2:  # Multiple violations - aggressive action\n",
    "            actions[\"max_new_tokens\"] = max(16, actions[\"max_new_tokens\"] - 12)\n",
    "            actions[\"throttle_ms\"] = min(100, actions[\"throttle_ms\"] + 30)\n",
    "            actions[\"temperature\"] = max(0.0, actions[\"temperature\"] - 0.15)\n",
    "        elif violations == 1:  # Single violation - moderate action\n",
    "            actions[\"max_new_tokens\"] = max(20, actions[\"max_new_tokens\"] - 6)\n",
    "            actions[\"throttle_ms\"] = min(50, actions[\"throttle_ms\"] + 15)\n",
    "            actions[\"temperature\"] = max(0.0, actions[\"temperature\"] - 0.1)\n",
    "        else:  # No violations - gradual recovery\n",
    "            actions[\"max_new_tokens\"] = min(60, actions[\"max_new_tokens\"] + 2)\n",
    "            actions[\"temperature\"] = min(0.5, actions[\"temperature\"] + 0.05)\n",
    "            \n",
    "        return actions\n",
    "\n",
    "    def aggregate_enhanced_kpis(self, df_runs, model_name, task_name, policy_type):\n",
    "        \"\"\"Enhanced KPI aggregation\"\"\"\n",
    "        \n",
    "        kpis = {\n",
    "            \"model\": model_name,\n",
    "            \"task\": task_name,\n",
    "            \"policy_type\": policy_type\n",
    "        }\n",
    "        \n",
    "        # Core performance metrics\n",
    "        for metric in [\"latency_ms\", \"ttft_ms\", \"tbt_mean_ms\", \"energy_Wh\", \"carbon_g\"]:\n",
    "            if metric in df_runs.columns:\n",
    "                data = df_runs[metric].dropna()\n",
    "                if not data.empty:\n",
    "                    kpis[f\"{metric}_mean\"] = float(data.mean())\n",
    "                    kpis[f\"{metric}_std\"] = float(data.std())\n",
    "                    kpis[f\"{metric}_p50\"] = float(data.median())\n",
    "                    kpis[f\"{metric}_p95\"] = float(np.percentile(data, 95))\n",
    "                    kpis[f\"{metric}_cv\"] = float(data.std() / data.mean()) if data.mean() > 0 else np.nan\n",
    "        \n",
    "        # Policy effectiveness metrics\n",
    "        if policy_type == \"saip\":\n",
    "            kpis[\"policy_effectiveness\"] = self.calculate_policy_effectiveness(df_runs)\n",
    "        \n",
    "        # Stability metrics\n",
    "        kpis[\"stability_score\"] = self.calculate_stability_score(df_runs)\n",
    "        \n",
    "        return kpis\n",
    "\n",
    "    def calculate_policy_effectiveness(self, df_runs):\n",
    "        \"\"\"Calculate policy effectiveness score\"\"\"\n",
    "        try:\n",
    "            # Measure how well the policy maintains target performance\n",
    "            cv = df_runs['latency_ms'].std() / df_runs['latency_ms'].mean()\n",
    "            p95 = np.percentile(df_runs['latency_ms'], 95)\n",
    "            \n",
    "            # Effectiveness is higher when CV is lower and P95 is controlled\n",
    "            effectiveness = 1 / (1 + cv) * (1 / (1 + p95 / 1000))\n",
    "            return float(effectiveness)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def calculate_stability_score(self, df_runs):\n",
    "        \"\"\"Calculate overall stability score\"\"\"\n",
    "        try:\n",
    "            # Multiple stability indicators\n",
    "            latency_cv = df_runs['latency_ms'].std() / df_runs['latency_ms'].mean()\n",
    "            energy_cv = df_runs['energy_Wh'].std() / df_runs['energy_Wh'].mean() if 'energy_Wh' in df_runs else 0\n",
    "            \n",
    "            # Lower CV means higher stability\n",
    "            stability = 1 / (1 + latency_cv + energy_cv)\n",
    "            return float(stability)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def create_comprehensive_visualizations(self, df_results, df_kpis, output_dir):\n",
    "        \"\"\"Create comprehensive visualizations\"\"\"\n",
    "        \n",
    "        print(\"üìä Creating Comprehensive Visualizations...\")\n",
    "        \n",
    "        # Set up plotting parameters\n",
    "        plt.rcParams['figure.figsize'] = (12, 8)\n",
    "        plt.rcParams['font.size'] = 10\n",
    "        \n",
    "        viz_dir = f\"{output_dir}/visualizations\"\n",
    "        \n",
    "        # 1. Performance Heatmap by Model and Task\n",
    "        if not df_kpis.empty:\n",
    "            try:\n",
    "                pivot_data = df_kpis[df_kpis['policy_type'] == 'baseline'].pivot_table(\n",
    "                    values='latency_ms_p95', \n",
    "                    index='model', \n",
    "                    columns='task', \n",
    "                    aggfunc='mean'\n",
    "                )\n",
    "                \n",
    "                plt.figure(figsize=(14, 10))\n",
    "                sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='RdYlBu_r', cbar_kws={'label': 'P95 Latency (ms)'})\n",
    "                plt.title('Model Performance Heatmap: P95 Latency by Model and Task', fontsize=16, pad=20)\n",
    "                plt.xlabel('Task', fontsize=12)\n",
    "                plt.ylabel('Model', fontsize=12)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.yticks(rotation=0)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{viz_dir}/performance_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(\"   ‚úÖ Performance heatmap saved\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Performance heatmap failed: {e}\")\n",
    "        \n",
    "        # 2. Policy Effectiveness Comparison\n",
    "        if not df_kpis.empty and 'policy_type' in df_kpis.columns:\n",
    "            try:\n",
    "                policy_comparison = df_kpis.groupby(['model', 'policy_type'])['latency_ms_p95'].mean().reset_index()\n",
    "                policy_pivot = policy_comparison.pivot(index='model', columns='policy_type', values='latency_ms_p95')\n",
    "                \n",
    "                if 'baseline' in policy_pivot.columns and 'saip' in policy_pivot.columns:\n",
    "                    policy_pivot['improvement'] = (policy_pivot['baseline'] - policy_pivot['saip']) / policy_pivot['baseline'] * 100\n",
    "                    \n",
    "                    plt.figure(figsize=(14, 8))\n",
    "                    policy_pivot['improvement'].plot(kind='bar', color='steelblue', alpha=0.8)\n",
    "                    plt.title('SAIP Policy Effectiveness: P95 Latency Improvement by Model', fontsize=16, pad=20)\n",
    "                    plt.xlabel('Model', fontsize=12)\n",
    "                    plt.ylabel('Improvement (%)', fontsize=12)\n",
    "                    plt.xticks(rotation=45, ha='right')\n",
    "                    plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f\"{viz_dir}/policy_effectiveness.png\", dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(\"   ‚úÖ Policy effectiveness chart saved\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Policy effectiveness chart failed: {e}\")\n",
    "        \n",
    "        # 3. Information Systems Quality Dashboard\n",
    "        if hasattr(self, 'is_quality_metrics') and self.is_quality_metrics:\n",
    "            try:\n",
    "                is_scores = []\n",
    "                for model, metrics in self.is_quality_metrics.items():\n",
    "                    is_scores.append({\n",
    "                        'model': model,\n",
    "                        'system_quality': np.mean(list(metrics['system_quality'].values())),\n",
    "                        'information_quality': np.mean(list(metrics['information_quality'].values())),\n",
    "                        'service_quality': np.mean(list(metrics['service_quality'].values())),\n",
    "                        'overall_score': metrics['overall_is_quality_score']\n",
    "                    })\n",
    "                \n",
    "                df_is = pd.DataFrame(is_scores)\n",
    "                \n",
    "                fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "                \n",
    "                # System Quality\n",
    "                df_is.set_index('model')['system_quality'].plot(kind='bar', ax=axes[0,0], color='lightblue')\n",
    "                axes[0,0].set_title('System Quality Scores')\n",
    "                axes[0,0].set_ylabel('Score')\n",
    "                axes[0,0].tick_params(axis='x', rotation=45)\n",
    "                \n",
    "                # Information Quality\n",
    "                df_is.set_index('model')['information_quality'].plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "                axes[0,1].set_title('Information Quality Scores')\n",
    "                axes[0,1].set_ylabel('Score')\n",
    "                axes[0,1].tick_params(axis='x', rotation=45)\n",
    "                \n",
    "                # Service Quality\n",
    "                df_is.set_index('model')['service_quality'].plot(kind='bar', ax=axes[1,0], color='lightcoral')\n",
    "                axes[1,0].set_title('Service Quality Scores')\n",
    "                axes[1,0].set_ylabel('Score')\n",
    "                axes[1,0].tick_params(axis='x', rotation=45)\n",
    "                \n",
    "                # Overall IS Quality\n",
    "                df_is.set_index('model')['overall_score'].plot(kind='bar', ax=axes[1,1], color='gold')\n",
    "                axes[1,1].set_title('Overall IS Quality Scores')\n",
    "                axes[1,1].set_ylabel('Score')\n",
    "                axes[1,1].tick_params(axis='x', rotation=45)\n",
    "                \n",
    "                plt.suptitle('Information Systems Quality Analysis Dashboard', fontsize=16)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{viz_dir}/is_quality_dashboard.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(\"   ‚úÖ IS Quality dashboard saved\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è IS Quality dashboard failed: {e}\")\n",
    "        \n",
    "        # 4. Technology Acceptance Model Visualization\n",
    "        if hasattr(self, 'tam_metrics') and self.tam_metrics:\n",
    "            try:\n",
    "                tam_scores = []\n",
    "                for model, metrics in self.tam_metrics.items():\n",
    "                    tam_scores.append({\n",
    "                        'model': model,\n",
    "                        'perceived_usefulness': metrics['perceived_usefulness']['overall_usefulness'],\n",
    "                        'perceived_ease_of_use': metrics['perceived_ease_of_use']['overall_ease_of_use'],\n",
    "                        'behavioral_intention': metrics['behavioral_intention'],\n",
    "                        'tam_score': metrics['tam_score']\n",
    "                    })\n",
    "                \n",
    "                df_tam = pd.DataFrame(tam_scores)\n",
    "                \n",
    "                # TAM Scatter Plot\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                scatter = plt.scatter(df_tam['perceived_usefulness'], df_tam['perceived_ease_of_use'], \n",
    "                                    c=df_tam['behavioral_intention'], s=100, alpha=0.7, cmap='viridis')\n",
    "                \n",
    "                for i, model in enumerate(df_tam['model']):\n",
    "                    plt.annotate(model, (df_tam['perceived_usefulness'].iloc[i], df_tam['perceived_ease_of_use'].iloc[i]), \n",
    "                               xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "                \n",
    "                plt.colorbar(scatter, label='Behavioral Intention to Use')\n",
    "                plt.xlabel('Perceived Usefulness', fontsize=12)\n",
    "                plt.ylabel('Perceived Ease of Use', fontsize=12)\n",
    "                plt.title('Technology Acceptance Model (TAM) Analysis', fontsize=16, pad=20)\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{viz_dir}/tam_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(\"   ‚úÖ TAM analysis chart saved\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è TAM analysis chart failed: {e}\")\n",
    "        \n",
    "        # 5. Econometric Results Visualization\n",
    "        if hasattr(self, 'econometric_models') and self.econometric_models:\n",
    "            try:\n",
    "                if 'technical_efficiency' in self.econometric_models:\n",
    "                    eff_data = self.econometric_models['technical_efficiency']\n",
    "                    \n",
    "                    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "                    \n",
    "                    # Latency Efficiency\n",
    "                    eff_data.set_index('model')['latency_efficiency'].plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "                    axes[0].set_title('Latency Efficiency by Model')\n",
    "                    axes[0].set_ylabel('Efficiency Score')\n",
    "                    axes[0].tick_params(axis='x', rotation=45)\n",
    "                    \n",
    "                    # Energy Efficiency\n",
    "                    eff_data.set_index('model')['energy_efficiency'].plot(kind='bar', ax=axes[1], color='lightgreen')\n",
    "                    axes[1].set_title('Energy Efficiency by Model')\n",
    "                    axes[1].set_ylabel('Efficiency Score')\n",
    "                    axes[1].tick_params(axis='x', rotation=45)\n",
    "                    \n",
    "                    # Overall Efficiency\n",
    "                    eff_data.set_index('model')['overall_efficiency'].plot(kind='bar', ax=axes[2], color='orange')\n",
    "                    axes[2].set_title('Overall Technical Efficiency')\n",
    "                    axes[2].set_ylabel('Efficiency Score')\n",
    "                    axes[2].tick_params(axis='x', rotation=45)\n",
    "                    \n",
    "                    plt.suptitle('Technical Efficiency Analysis', fontsize=16)\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f\"{viz_dir}/technical_efficiency.png\", dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(\"   ‚úÖ Technical efficiency chart saved\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Technical efficiency chart failed: {e}\")\n",
    "\n",
    "    def save_comprehensive_results(self, df_results, df_kpis, output_dir):\n",
    "        \"\"\"Save all results to various formats\"\"\"\n",
    "        \n",
    "        print(\"üíæ Saving Comprehensive Results...\")\n",
    "        \n",
    "        data_dir = f\"{output_dir}/data\"\n",
    "        \n",
    "        # 1. Save to Excel with multiple sheets\n",
    "        excel_path = f\"{data_dir}/comprehensive_results.xlsx\"\n",
    "        with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "            \n",
    "            # Main results\n",
    "            df_results.to_excel(writer, sheet_name='Raw_Results', index=False)\n",
    "            df_kpis.to_excel(writer, sheet_name='KPI_Summary', index=False)\n",
    "            \n",
    "            # IS Quality metrics\n",
    "            if hasattr(self, 'is_quality_metrics') and self.is_quality_metrics:\n",
    "                is_data = []\n",
    "                for model, metrics in self.is_quality_metrics.items():\n",
    "                    row = {'model': model}\n",
    "                    row.update(metrics['system_quality'])\n",
    "                    row.update(metrics['information_quality'])\n",
    "                    row.update(metrics['service_quality'])\n",
    "                    row['overall_is_quality_score'] = metrics['overall_is_quality_score']\n",
    "                    is_data.append(row)\n",
    "                pd.DataFrame(is_data).to_excel(writer, sheet_name='IS_Quality', index=False)\n",
    "            \n",
    "            # TAM metrics\n",
    "            if hasattr(self, 'tam_metrics') and self.tam_metrics:\n",
    "                tam_data = []\n",
    "                for model, metrics in self.tam_metrics.items():\n",
    "                    row = {'model': model}\n",
    "                    row.update(metrics['perceived_usefulness'])\n",
    "                    row.update(metrics['perceived_ease_of_use'])\n",
    "                    row['behavioral_intention'] = metrics['behavioral_intention']\n",
    "                    row['tam_score'] = metrics['tam_score']\n",
    "                    tam_data.append(row)\n",
    "                pd.DataFrame(tam_data).to_excel(writer, sheet_name='TAM_Analysis', index=False)\n",
    "            \n",
    "            # Econometric results\n",
    "            if hasattr(self, 'econometric_models') and self.econometric_models:\n",
    "                if 'technical_efficiency' in self.econometric_models:\n",
    "                    self.econometric_models['technical_efficiency'].to_excel(\n",
    "                        writer, sheet_name='Technical_Efficiency', index=False\n",
    "                    )\n",
    "        \n",
    "        print(f\"   ‚úÖ Excel results saved: {excel_path}\")\n",
    "        \n",
    "        # 2. Save to CSV files\n",
    "        df_results.to_csv(f\"{data_dir}/raw_results.csv\", index=False)\n",
    "        df_kpis.to_csv(f\"{data_dir}/kpi_summary.csv\", index=False)\n",
    "        print(\"   ‚úÖ CSV files saved\")\n",
    "        \n",
    "        # 3. Save to JSON for web applications\n",
    "        results_json = {\n",
    "            'summary': {\n",
    "                'total_observations': len(df_results),\n",
    "                'models_analyzed': df_results['model'].nunique() if 'model' in df_results else 0,\n",
    "                'tasks_analyzed': df_results['task'].nunique() if 'task' in df_results else 0,\n",
    "                'analysis_timestamp': datetime.now().isoformat()\n",
    "            },\n",
    "            'kpis': df_kpis.to_dict('records') if not df_kpis.empty else [],\n",
    "            'is_quality': self.is_quality_metrics if hasattr(self, 'is_quality_metrics') else {},\n",
    "            'tam_analysis': self.tam_metrics if hasattr(self, 'tam_metrics') else {}\n",
    "        }\n",
    "        \n",
    "        with open(f\"{data_dir}/comprehensive_analysis.json\", 'w') as f:\n",
    "            json.dump(results_json, f, indent=2, default=str)\n",
    "        print(\"   ‚úÖ JSON results saved\")\n",
    "        \n",
    "        # 4. Save econometric model summaries\n",
    "        if hasattr(self, 'econometric_models') and self.econometric_models:\n",
    "            models_dir = f\"{output_dir}/models\"\n",
    "            \n",
    "            for model_name, model_data in self.econometric_models.items():\n",
    "                if 'model' in model_data and hasattr(model_data['model'], 'summary'):\n",
    "                    with open(f\"{models_dir}/{model_name}_summary.txt\", 'w') as f:\n",
    "                        f.write(str(model_data['model'].summary()))\n",
    "            \n",
    "            print(\"   ‚úÖ Econometric model summaries saved\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üöÄ Enhanced SAIP Benchmarking System\")\n",
    "    print(\"   Information Systems Theory + Econometric Analysis\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = EnhancedSAIPAnalyzer()\n",
    "    output_dir = analyzer.setup_directories()\n",
    "    \n",
    "    # Load data (using the same in-memory data as before)\n",
    "    print(\"\\nüìÇ Loading Data...\")\n",
    "    \n",
    "    # Data for df_main_raw (same as before)\n",
    "    main_data_str = \"\"\"\n",
    "    Model\tTask\tPrecision\tRecall\tf1_score\tLatency Avg (ms)\tLatency Std (ms)\tLatency Min (ms)\tLatency Max (ms)\tLatency P10 (ms)\tLatency P25 (ms)\tLatency P50 (ms)\tLatency P75 (ms)\tLatency P90 (ms)\tLatency P95 (ms)\tLatency P99 (ms)\tthroughput_tokens_per_sec\tToken Efficiency (tokens/sec)\tCPU Memory Avg (MB)\tÌååÎùºÎØ∏ÌÑ∞_b\tÏµúÎåÄ ÏãúÌÄÄÏä§ Í∏∏Ïù¥\tÎ≥ëÎ†¨ ÌÅ¨Í∏∞\tÏª¥ÌååÏùº ÏÜåÏöî\tSerialize(Ï¥à)\tnum_blocks\tBest Batch\tKV per token (MB)\tÏòàÏÉÅ Ïª®ÌÖçÏä§Ìä∏ 4K Ïãú KV (GB)\tpeak_npu_mem_Ìú¥\tÏòàÏÉÅ Ï†ÑÎ†• (W)\tTracing(Ï¥à)\tModel Conversion(Ï¥à)\tÏµúÏ¢Ö Serialize(Ï¥à)\t2K ÌÜ†ÌÅ∞(GB)\t4K ÌÜ†ÌÅ∞(GB)\t8K ÌÜ†ÌÅ∞(GB)\t16K ÌÜ†ÌÅ∞(GB)\n",
    "    DeepSeek-R1-Distill-Qwen-1.5B\tNLU\t0.57\t1\t0.7261\t639\t492.75\t146.92\t1431.13\t182.27\t183.34\t564.66\t1060.25\t1413.59\t1416.72\t1426.1\t35.43\t34.73\t8226.95\t1.5\t131072\t1\t1:44\t3\t9\t1\t0.35\t1.4\t6\t13.5\t2\t36\t2\t5\t6\t8.5\t13.5\n",
    "    EXAONE-3.5-2.4B-Instruct\tNLU\t0.57\t1\t0.7261\t75.59\t4.85\t72.18\t102.25\t73.88\t74.47\t74.66\t74.92\t75.31\t77.23\t98.58\t26.46\t26.54\t9691.05\t2.4\t32768\t1\t2:05\t3\t1\t1\t0.42\t1.7\t7\t16.5\t2\t46\t1\t6.5\t7.2\t10.5\t17\n",
    "    gemma-2b-it\tNLU\t0.57\t1\t0.7261\t67.61\t55.58\t61.11\t619.68\t61.17\t61.26\t61.61\t61.88\t63.07\t63.26\t98.78\t32.99\t32.38\t14093.04\t2\t8192\t1\t1:25\t4\t1\t1.5\t0.4\t1.6\t6.5\t14.5\t1.5\t24\t4\t5.8\t6.5\t9.5\t15.5\n",
    "    Llama-3.2-3B-Instruct\tNLU\t0.57\t1\t0.7261\t1400.24\t1030.52\t90.42\t2481.65\t106.11\t107\t2197.27\t2219.14\t2231.39\t2245.64\t2397.88\t22.34\t21.01\t13352\t3.2\t32768\t1\t1:46\t5\t9\t1\t0.002\t0.008\t16\t120\t2\t36\t5\t7.6\t8.5\t13\t22\n",
    "    Midm-2.0-Mini-Instruct\tNLU\t0.57\t1\t0.7261\t115.62\t6.57\t103.8\t164.88\t109.02\t114.98\t115.5\t116.59\t117.21\t123.73\t134.91\t17.3\t17.34\t9127.88\t2\t32768\t1\t2:43\t3\t1\t1\t0.46\t1.8\t7.5\t17.5\t4\t63\t1\t5.8\t6.5\t9.5\t15.5\n",
    "    opt-2.7b\tNLU\t0.57\t1\t0.7261\t1314.69\t73.94\t1259.12\t1553.53\t1264.56\t1279.11\t1281.13\t1313.08\t1443.6\t1530.26\t1543.72\t38.03\t38.14\t8066\t2.7\t2048\t1\t1:34\t3\t1\t1\t0.45\t1.8\t7.2\t15.5\t4\t22\t2\t6.5\t7.2\t10.5\t17\n",
    "    Qwen2.5-0.5B-Instruct\tNLU\t0.57\t1\t0.7261\t550.55\t81.81\t273.27\t885.9\t428.81\t563.91\t581.57\t582.53\t584.12\t588.68\t649.71\t84.88\t85.05\t4139.33\t0.5\t32768\t1\t0:39\t1\t1\t3\t0.18\t0.7\t3\t9\t2\t32\t0.5\t3\t3.7\t5\t7.6\n",
    "    Qwen2.5-1.5B-Instruct\tNLU\t0.57\t1\t0.7261\t244.01\t440.3\t54.32\t1381.94\t66.77\t66.81\t66.86\t66.94\t1337.52\t1379.31\t1381.42\t34.96\t30.85\t7607.46\t1.5\t32768\t1\t1:12\t2\t1\t1.5\t0.32\t1.3\t5.8\t13\t2\t38\t1.5\t5\t6\t8.5\t13.5\n",
    "    Qwen2.5-3B-Instruct\tNLU\t0.57\t1\t0.7261\t1130.91\t1029.74\t95.37\t2561.1\t108.67\t115.8\t998.33\t2246.19\t2284.49\t2290.96\t2344.85\t21.95\t19.98\t11784.5\t3\t32768\t1\t2:05\t4\t1\t1\t0.55\t2.2\t8\t18\t2\t51\t2\t7.6\t8.5\t13\t22\n",
    "    DeepSeek-R1-Distill-Qwen-1.5B\tQA\t0.0089\t0.48\t0.0173\t1362.23\t195.48\t442.8\t1696.66\t1202.29\t1313.74\t1440.25\t1455.3\t1486.74\t1511.4\t1692.69\t35.14\t35.2\t8250.61\t1.5\t131072\t1\t1:44\t3\t9\t1\t0.35\t1.4\t6\t13.5\t2\t36\t2\t5\t6\t8.5\t13.5\n",
    "    EXAONE-3.5-2.4B-Instruct\tQA\t0.0095\t0.48\t0.0184\t1092.26\t368.34\t121.11\t1710.39\t525.48\t802.69\t1250.16\t1321.26\t1523.49\t1535.27\t1582.61\t36.29\t35.88\t9712.48\t2.4\t32768\t1\t2:05\t3\t1\t1\t0.42\t1.7\t7\t16.5\t2\t46\t1\t6.5\t7.2\t10.5\t17\n",
    "    gemma-2b-it\tQA\t0.0099\t0.48\t0.0192\t711.26\t223.91\t293.32\t1322.1\t423.07\t573.75\t701.81\t808.63\t978.48\t1141.22\t1303.94\t36.54\t36.22\t14100.66\t2\t8192\t1\t1:25\t4\t1\t1.5\t0.4\t1.6\t6.5\t14.5\t1.5\t24\t4\t5.8\t6.5\t9.5\t15.5\n",
    "    Llama-3.2-3B-Instruct\tQA\t0.0097\t0.48\t0.0188\t1621.36\t671.81\t245.42\t2661.65\t684.8\t1036.15\t1758.09\t2269.7\t2314.97\t2336.89\t2416.83\t21.58\t21.31\t13374.42\t3.2\t32768\t1\t1:46\t5\t9\t1\t0.002\t0.008\t16\t120\t2\t36\t5\t7.6\t8.5\t13\t22\n",
    "    Midm-2.0-Mini-Instruct\tQA\t0.0099\t0.48\t0.0192\t1064.67\t396\t533.45\t2307.55\t684.26\t777.68\t964.41\t1221.03\t1637.91\t1919.04\t2132.56\t22.7\t22.54\t9143.92\t2\t32768\t1\t2:43\t3\t1\t1\t0.46\t1.8\t7.5\t17.5\t4\t63\t1\t5.8\t6.5\t9.5\t15.5\n",
    "    opt-2.7b\tQA\t0.0092\t0.48\t0.0178\t1392.5\t86.75\t1285.18\t1665.51\t1321.21\t1333.97\t1371.68\t1419.6\t1531.78\t1603.39\t1656.68\t35.91\t36.03\t8084.59\t2.7\t2048\t1\t1:34\t3\t1\t1\t0.45\t1.8\t7.2\t15.5\t4\t22\t2\t6.5\t7.2\t10.5\t17\n",
    "    Qwen2.5-0.5B-Instruct\tQA\t0.0088\t0.48\t0.0172\t585.66\t105.11\t149.29\t1137.48\t507.3\t591.66\t596.35\t601.99\t613.49\t640.59\t945.22\t81.51\t81.9\t4158.77\t0.5\t32768\t1\t0:39\t1\t1\t3\t0.18\t0.7\t3\t9\t2\t32\t0.5\t3\t3.7\t5\t7.6\n",
    "    Qwen2.5-1.5B-Instruct\tQA\t0.009\t0.48\t0.0175\t1299.95\t252.15\t263.69\t1495.1\t768.12\t1340.44\t1402.14\t1413.14\t1445.91\t1468.63\t1489.8\t35.69\t35.6\t7628.45\t1.5\t32768\t1\t1:12\t2\t1\t1.5\t0.32\t1.3\t5.8\t13\t2\t38\t1.5\t5\t6\t8.5\t13.5\n",
    "    Qwen2.5-3B-Instruct\tQA\t0.009\t0.48\t0.0175\t2206.83\t406.22\t610.79\t2961.56\t1638.76\t2265.47\t2330.8\t2365.1\t2411.44\t2448.82\t2720.45\t21.26\t21.27\t11806.66\t3\t32768\t1\t2:05\t4\t1\t1\t0.55\t2.2\t8\t18\t2\t51\t2\t7.6\t8.5\t13\t22\n",
    "    DeepSeek-R1-Distill-Qwen-1.5B\tSummarization\t0.0792\t0.9046\t0.1433\t1614.53\t147.35\t1215.81\t1968.53\t1472.44\t1523.43\t1582.53\t1685.63\t1834.01\t1891.5\t1957.85\t30.97\t31.23\t8265.59\t1.5\t131072\t1\t1:44\t3\t9\t1\t0.35\t1.4\t6\t13.5\t2\t36\t2\t5\t6\t8.5\t13.5\n",
    "    EXAONE-3.5-2.4B-Instruct\tSummarization\t0.0799\t0.9069\t0.1446\t1628.44\t249.6\t1267.73\t2442.68\t1362.03\t1413.82\t1602.61\t1776.01\t2018.68\t2090.75\t2231.78\t30.7\t31.37\t9733.12\t2.4\t32768\t1\t2:05\t3\t1\t1\t0.42\t1.7\t7\t16.5\t2\t46\t1\t6.5\t7.2\t10.5\t17\n",
    "    gemma-2b-it\tSummarization\t0.0797\t0.9044\t0.1441\t1480.64\t272.46\t471.63\t2061.3\t1261.5\t1375.2\t1487.86\t1654.11\t1782.58\t1866.11\t1989.55\t31.8\t31.76\t14114.01\t2\t8192\t1\t1:25\t4\t1\t1.5\t0.4\t1.6\t6.5\t14.5\t1.5\t24\t4\t5.8\t6.5\t9.5\t15.5\n",
    "    Llama-3.2-3B-Instruct\tSummarization\t0.0795\t0.9056\t0.1439\t2579.09\t205.32\t2280.68\t3098.51\t2355.64\t2413.21\t2535.3\t2691.54\t2893.23\t3006.32\t3081.16\t19.39\t19.5\t13385.61\t3.2\t32768\t1\t1:46\t5\t9\t1\t0.002\t0.008\t16\t120\t2\t36\t5\t7.6\t8.5\t13\t22\n",
    "    Midm-2.0-Mini-Instruct\tSummarization\t0.0796\t0.9036\t0.144\t2443.11\t326.29\t1965.53\t3766.72\t2162.48\t2208.67\t2323.79\t2591.71\t2869.08\t2993.27\t3568.25\t20.47\t20.79\t9169.49\t2\t32768\t1\t2:43\t3\t1\t1\t0.46\t1.8\t7.5\t17.5\t4\t63\t1\t5.8\t6.5\t9.5\t15.5\n",
    "    opt-2.7b\tSummarization\t0.0813\t0.8996\t0.1468\t1689.43\t249.71\t1338.42\t2427.64\t1428.19\t1492.03\t1642.76\t1838.14\t2071.59\t2166.29\t2342.45\t29.6\t30.2\t8095.09\t2.7\t2048\t1\t1:34\t3\t1\t1\t0.45\t1.8\t7.2\t15.5\t4\t22\t2\t6.5\t7.2\t10.5\t17\n",
    "    Qwen2.5-0.5B-Instruct\tSummarization\t0.0795\t0.9056\t0.1438\t697.54\t74.53\t591.98\t933.24\t613.67\t634.84\t676.85\t743.1\t795.81\t843.44\t870.1\t71.55\t72.31\t4169.39\t0.5\t32768\t1\t0:39\t1\t1\t3\t0.18\t0.7\t3\t9\t2\t32\t0.5\t3\t3.7\t5\t7.6\n",
    "    Qwen2.5-1.5B-Instruct\tSummarization\t0.0798\t0.908\t0.1444\t1533.75\t155.2\t1174.59\t2022.64\t1341.06\t1447.21\t1510.19\t1609.57\t1743.97\t1804.24\t2008.48\t32.6\t32.93\t7644.25\t1.5\t32768\t1\t1:12\t2\t1\t1.5\t0.32\t1.3\t5.8\t13\t2\t38\t1.5\t5\t6\t8.5\t13.5\n",
    "    Qwen2.5-3B-Instruct\tSummarization\t0.0799\t0.9073\t0.1445\t2651.29\t255.3\t2319.95\t3763.13\t2375.9\t2465.56\t2594.74\t2779.22\t2989.27\t3098.85\t3462.91\t18.86\t19.02\t11818.7\t3\t32768\t1\t2:05\t4\t1\t1\t0.55\t2.2\t8\t18\t2\t51\t2\t7.6\t8.5\t13\t22\n",
    "    \"\"\"\n",
    "    df_main_raw = pd.read_csv(io.StringIO(main_data_str), sep='\\t')\n",
    "\n",
    "    # Load time-series data\n",
    "    user_desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    path_ts = os.path.join(user_desktop, r\"ÎÖºÎ¨∏\\ÌõÑÏÜçÎÖºÎ¨∏(16) sLLM ÌñâÎèôÎ™®Ìòï\\[Î∂ÑÏÑù] Data_ÏãúÍ≥ÑÏó¥.xlsx\")\n",
    "    \n",
    "    try:\n",
    "        df_ts_raw = pd.read_excel(path_ts, sheet_name=0)\n",
    "        print(f\"   ‚úÖ Loaded {len(df_ts_raw)} time-series observations\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed to load time-series data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # HuggingFace data (minimal for this example)\n",
    "    df_hf_raw = pd.DataFrame({'Ìï≠Î™©': ['placeholder'], 'value': ['placeholder']})\n",
    "    \n",
    "    # Data preparation\n",
    "    df_ts_clean, df_final_analysis = analyzer.load_and_prepare_enhanced_data(df_main_raw, df_hf_raw, df_ts_raw)\n",
    "    \n",
    "    if df_ts_clean is None or df_final_analysis is None:\n",
    "        print(\"‚ùå Data preparation failed\")\n",
    "        return\n",
    "    \n",
    "    # Create advanced simulator\n",
    "    generate_fn, power_fn = analyzer.create_advanced_simulator(df_ts_clean, df_final_analysis)\n",
    "    \n",
    "    # Run comprehensive simulation\n",
    "    df_results, df_kpis = analyzer.comprehensive_simulation(generate_fn, power_fn, df_final_analysis, df_ts_clean)\n",
    "    \n",
    "    if df_results.empty:\n",
    "        print(\"‚ùå No simulation results generated\")\n",
    "        return\n",
    "    \n",
    "    # Information Systems Quality Analysis\n",
    "    is_quality = analyzer.information_systems_quality_analysis(df_results)\n",
    "    \n",
    "    # Technology Acceptance Model Analysis  \n",
    "    tam_analysis = analyzer.technology_acceptance_model_analysis(df_results, df_final_analysis)\n",
    "    \n",
    "    # Econometric Analysis\n",
    "    econometric_results = analyzer.econometric_analysis(df_results, df_final_analysis)\n",
    "    \n",
    "    # Create visualizations\n",
    "    analyzer.create_comprehensive_visualizations(df_results, df_kpis, output_dir)\n",
    "    \n",
    "    # Save all results\n",
    "    analyzer.save_comprehensive_results(df_results, df_kpis, output_dir)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéâ Enhanced SAIP Analysis Complete!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìä Total Observations: {len(df_results):,}\")\n",
    "    print(f\"ü§ñ Models Analyzed: {df_results['model'].nunique()}\")\n",
    "    print(f\"üìã Tasks Analyzed: {df_results['task'].nunique()}\")\n",
    "    print(f\"üìà KPI Records: {len(df_kpis):,}\")\n",
    "    print(f\"üìÅ Results saved to: {output_dir}\")\n",
    "    \n",
    "    # Display top performers\n",
    "    if not df_kpis.empty:\n",
    "        baseline_kpis = df_kpis[df_kpis['policy_type'] == 'baseline']\n",
    "        if not baseline_kpis.empty:\n",
    "            best_latency = baseline_kpis.loc[baseline_kpis['latency_ms_p95'].idxmin()]\n",
    "            best_efficiency = baseline_kpis.loc[baseline_kpis['energy_Wh_mean'].idxmin()] if 'energy_Wh_mean' in baseline_kpis else None\n",
    "            \n",
    "            print(f\"\\nüèÜ Best Performance:\")\n",
    "            print(f\"   Lowest P95 Latency: {best_latency['model']} ({best_latency['latency_ms_p95']:.1f} ms)\")\n",
    "            if best_efficiency is not None:\n",
    "                print(f\"   Most Energy Efficient: {best_efficiency['model']} ({best_efficiency['energy_Wh_mean']:.4f} Wh/req)\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Analysis completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
